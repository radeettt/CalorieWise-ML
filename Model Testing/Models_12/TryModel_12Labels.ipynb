{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import InceptionV3\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "import cv2 as cv\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'train_set_ex'\n",
    "validation_dir = 'validation_set_ex'\n",
    "test_dir = 'test_set_ex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3267 images belonging to 12 classes.\n",
      "Found 1267 images belonging to 12 classes.\n",
      "Found 564 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create ImageDataGenerators for training, validation, and testing\n",
    "batch_size = 32\n",
    "target_size = (256, 256)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_dataset = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_dataset = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=1,  # Set batch_size to 1 for testing\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bakso': 0,\n",
       " 'Caesar Salad': 1,\n",
       " 'Kerang Tiram': 2,\n",
       " 'Nasi': 3,\n",
       " 'Nasi Goreng': 4,\n",
       " 'Sate Ayam': 5,\n",
       " 'Sayap Ayam Goreng': 6,\n",
       " 'Siomay': 7,\n",
       " 'Spaghetti': 8,\n",
       " 'Steak': 9,\n",
       " 'Telur Balado': 10,\n",
       " 'Yoghurt': 11}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set the number of batches to visualize\n",
    "# num_batches_to_visualize = 3\n",
    "\n",
    "# # Iterate over batches and show images\n",
    "# for batch_num in range(3):\n",
    "#     # Get a batch from the training dataset\n",
    "#     images, labels = train_dataset.next()\n",
    "\n",
    "#     # Display the images in a grid\n",
    "#     plt.figure(figsize=(12, 12))\n",
    "#     for i in range(batch_size):\n",
    "#         plt.subplot(2, 4, i + 1)\n",
    "#         plt.imshow(images[i])\n",
    "        \n",
    "#         # Assuming you have a list of class names\n",
    "#         classes = train_dataset.class_indices\n",
    "#         class_index = np.argmax(labels[i])\n",
    "#         class_name = [k for k, v in classes.items() if v == class_index][0]\n",
    "        \n",
    "#         plt.title(class_name)\n",
    "#         plt.axis('off')\n",
    "\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "103/103 [==============================] - 36s 345ms/step - loss: 2.2103 - accuracy: 0.2063 - val_loss: 2.0253 - val_accuracy: 0.3204\n",
      "Epoch 2/200\n",
      "103/103 [==============================] - 34s 328ms/step - loss: 1.9350 - accuracy: 0.3159 - val_loss: 1.8164 - val_accuracy: 0.3915\n",
      "Epoch 3/200\n",
      "103/103 [==============================] - 34s 334ms/step - loss: 1.8263 - accuracy: 0.3612 - val_loss: 1.6970 - val_accuracy: 0.4309\n",
      "Epoch 4/200\n",
      "103/103 [==============================] - 33s 322ms/step - loss: 1.7498 - accuracy: 0.4034 - val_loss: 1.6600 - val_accuracy: 0.4522\n",
      "Epoch 5/200\n",
      "103/103 [==============================] - 36s 350ms/step - loss: 1.6930 - accuracy: 0.4249 - val_loss: 1.6290 - val_accuracy: 0.4799\n",
      "Epoch 6/200\n",
      "103/103 [==============================] - 33s 323ms/step - loss: 1.6405 - accuracy: 0.4539 - val_loss: 1.5929 - val_accuracy: 0.4728\n",
      "Epoch 7/200\n",
      "103/103 [==============================] - 33s 321ms/step - loss: 1.5766 - accuracy: 0.4607 - val_loss: 1.5027 - val_accuracy: 0.4996\n",
      "Epoch 8/200\n",
      "103/103 [==============================] - 34s 327ms/step - loss: 1.5386 - accuracy: 0.4867 - val_loss: 1.5661 - val_accuracy: 0.4815\n",
      "Epoch 9/200\n",
      "103/103 [==============================] - 34s 326ms/step - loss: 1.5143 - accuracy: 0.4879 - val_loss: 1.4869 - val_accuracy: 0.5130\n",
      "Epoch 10/200\n",
      "103/103 [==============================] - 33s 320ms/step - loss: 1.4670 - accuracy: 0.5038 - val_loss: 1.3894 - val_accuracy: 0.5351\n",
      "Epoch 11/200\n",
      "103/103 [==============================] - 33s 321ms/step - loss: 1.4262 - accuracy: 0.5277 - val_loss: 1.4809 - val_accuracy: 0.5170\n",
      "Epoch 12/200\n",
      "103/103 [==============================] - 34s 329ms/step - loss: 1.4244 - accuracy: 0.5280 - val_loss: 1.4606 - val_accuracy: 0.5138\n",
      "Epoch 13/200\n",
      "103/103 [==============================] - 34s 328ms/step - loss: 1.4194 - accuracy: 0.5265 - val_loss: 1.4101 - val_accuracy: 0.5288\n",
      "Epoch 14/200\n",
      "103/103 [==============================] - 33s 324ms/step - loss: 1.3356 - accuracy: 0.5497 - val_loss: 1.4874 - val_accuracy: 0.5146\n",
      "Epoch 15/200\n",
      "103/103 [==============================] - 33s 323ms/step - loss: 1.3351 - accuracy: 0.5617 - val_loss: 1.4542 - val_accuracy: 0.5193\n",
      "Epoch 16/200\n",
      "103/103 [==============================] - 34s 325ms/step - loss: 1.3105 - accuracy: 0.5629 - val_loss: 1.3216 - val_accuracy: 0.5612\n",
      "Epoch 17/200\n",
      "103/103 [==============================] - 33s 323ms/step - loss: 1.3068 - accuracy: 0.5706 - val_loss: 1.4309 - val_accuracy: 0.5320\n",
      "Epoch 18/200\n",
      "103/103 [==============================] - 34s 325ms/step - loss: 1.2840 - accuracy: 0.5724 - val_loss: 1.2937 - val_accuracy: 0.5667\n",
      "Epoch 19/200\n",
      "103/103 [==============================] - 34s 326ms/step - loss: 1.2690 - accuracy: 0.5852 - val_loss: 1.3025 - val_accuracy: 0.5746\n",
      "Epoch 20/200\n",
      "103/103 [==============================] - 35s 337ms/step - loss: 1.2628 - accuracy: 0.5880 - val_loss: 1.5529 - val_accuracy: 0.5012\n",
      "Epoch 21/200\n",
      "103/103 [==============================] - 34s 328ms/step - loss: 1.2465 - accuracy: 0.5917 - val_loss: 1.2538 - val_accuracy: 0.5888\n",
      "Epoch 22/200\n",
      "103/103 [==============================] - 34s 328ms/step - loss: 1.2209 - accuracy: 0.5963 - val_loss: 1.2563 - val_accuracy: 0.5991\n",
      "Epoch 23/200\n",
      "103/103 [==============================] - 35s 341ms/step - loss: 1.1871 - accuracy: 0.6058 - val_loss: 1.4197 - val_accuracy: 0.5549\n",
      "Epoch 24/200\n",
      "103/103 [==============================] - 35s 336ms/step - loss: 1.2088 - accuracy: 0.5862 - val_loss: 1.2138 - val_accuracy: 0.5943\n",
      "Epoch 25/200\n",
      "103/103 [==============================] - 35s 335ms/step - loss: 1.1536 - accuracy: 0.6146 - val_loss: 1.1760 - val_accuracy: 0.6125\n",
      "Epoch 26/200\n",
      "103/103 [==============================] - 37s 359ms/step - loss: 1.1572 - accuracy: 0.6201 - val_loss: 1.2718 - val_accuracy: 0.5912\n",
      "Epoch 27/200\n",
      "103/103 [==============================] - 35s 342ms/step - loss: 1.1658 - accuracy: 0.6125 - val_loss: 1.1538 - val_accuracy: 0.6140\n",
      "Epoch 28/200\n",
      "103/103 [==============================] - 34s 333ms/step - loss: 1.1317 - accuracy: 0.6198 - val_loss: 1.1774 - val_accuracy: 0.6180\n",
      "Epoch 29/200\n",
      "103/103 [==============================] - 35s 334ms/step - loss: 1.1327 - accuracy: 0.6116 - val_loss: 1.1716 - val_accuracy: 0.6156\n",
      "Epoch 30/200\n",
      "103/103 [==============================] - 34s 326ms/step - loss: 1.1302 - accuracy: 0.6278 - val_loss: 1.2377 - val_accuracy: 0.5975\n",
      "Epoch 31/200\n",
      "103/103 [==============================] - 34s 324ms/step - loss: 1.0779 - accuracy: 0.6492 - val_loss: 1.2294 - val_accuracy: 0.5983\n",
      "Epoch 32/200\n",
      "103/103 [==============================] - 34s 334ms/step - loss: 1.0934 - accuracy: 0.6364 - val_loss: 1.1964 - val_accuracy: 0.6054\n",
      "Epoch 33/200\n",
      "103/103 [==============================] - 35s 339ms/step - loss: 1.0677 - accuracy: 0.6410 - val_loss: 1.1012 - val_accuracy: 0.6346\n",
      "Epoch 34/200\n",
      "103/103 [==============================] - 35s 335ms/step - loss: 1.0401 - accuracy: 0.6553 - val_loss: 1.1794 - val_accuracy: 0.6196\n",
      "Epoch 35/200\n",
      "103/103 [==============================] - 35s 339ms/step - loss: 1.0774 - accuracy: 0.6391 - val_loss: 1.1482 - val_accuracy: 0.6164\n",
      "Epoch 36/200\n",
      "103/103 [==============================] - 34s 329ms/step - loss: 1.0468 - accuracy: 0.6440 - val_loss: 1.3526 - val_accuracy: 0.5770\n",
      "Epoch 37/200\n",
      "103/103 [==============================] - 35s 338ms/step - loss: 1.0241 - accuracy: 0.6541 - val_loss: 1.0795 - val_accuracy: 0.6377\n",
      "Epoch 38/200\n",
      "103/103 [==============================] - 35s 341ms/step - loss: 1.0359 - accuracy: 0.6501 - val_loss: 1.3301 - val_accuracy: 0.5762\n",
      "Epoch 39/200\n",
      "103/103 [==============================] - 34s 331ms/step - loss: 1.0069 - accuracy: 0.6621 - val_loss: 1.0928 - val_accuracy: 0.6385\n",
      "Epoch 40/200\n",
      "103/103 [==============================] - 35s 340ms/step - loss: 0.9820 - accuracy: 0.6605 - val_loss: 1.1512 - val_accuracy: 0.6298\n",
      "Epoch 41/200\n",
      "103/103 [==============================] - 34s 328ms/step - loss: 0.9944 - accuracy: 0.6710 - val_loss: 1.0901 - val_accuracy: 0.6401\n",
      "Epoch 42/200\n",
      "103/103 [==============================] - 34s 325ms/step - loss: 0.9848 - accuracy: 0.6835 - val_loss: 1.2307 - val_accuracy: 0.6062\n",
      "Epoch 43/200\n",
      "103/103 [==============================] - 43s 419ms/step - loss: 0.9796 - accuracy: 0.6734 - val_loss: 1.3868 - val_accuracy: 0.5627\n",
      "Epoch 44/200\n",
      "103/103 [==============================] - 41s 393ms/step - loss: 0.9925 - accuracy: 0.6654 - val_loss: 1.2200 - val_accuracy: 0.6038\n",
      "Epoch 45/200\n",
      "103/103 [==============================] - 33s 320ms/step - loss: 0.9865 - accuracy: 0.6774 - val_loss: 1.1014 - val_accuracy: 0.6480\n",
      "Epoch 46/200\n",
      "103/103 [==============================] - 33s 320ms/step - loss: 0.9480 - accuracy: 0.6838 - val_loss: 1.1942 - val_accuracy: 0.6188\n",
      "Epoch 47/200\n",
      "103/103 [==============================] - 33s 324ms/step - loss: 0.9425 - accuracy: 0.6838 - val_loss: 1.0855 - val_accuracy: 0.6488\n",
      "Epoch 48/200\n",
      "103/103 [==============================] - 33s 323ms/step - loss: 0.9312 - accuracy: 0.6902 - val_loss: 1.1814 - val_accuracy: 0.6290\n",
      "Epoch 49/200\n",
      "103/103 [==============================] - 33s 322ms/step - loss: 0.9367 - accuracy: 0.6804 - val_loss: 1.0322 - val_accuracy: 0.6606\n",
      "Epoch 50/200\n",
      "103/103 [==============================] - 33s 323ms/step - loss: 0.9282 - accuracy: 0.6918 - val_loss: 1.0028 - val_accuracy: 0.6638\n",
      "Epoch 51/200\n",
      "103/103 [==============================] - 33s 322ms/step - loss: 0.9192 - accuracy: 0.7022 - val_loss: 1.0608 - val_accuracy: 0.6535\n",
      "Epoch 52/200\n",
      "103/103 [==============================] - 36s 349ms/step - loss: 0.8953 - accuracy: 0.7080 - val_loss: 1.0934 - val_accuracy: 0.6417\n",
      "Epoch 53/200\n",
      "103/103 [==============================] - 34s 331ms/step - loss: 0.8825 - accuracy: 0.7071 - val_loss: 1.0564 - val_accuracy: 0.6582\n",
      "Epoch 54/200\n",
      "103/103 [==============================] - 34s 325ms/step - loss: 0.8697 - accuracy: 0.7178 - val_loss: 1.0996 - val_accuracy: 0.6480\n",
      "Epoch 55/200\n",
      "103/103 [==============================] - 34s 328ms/step - loss: 0.8639 - accuracy: 0.7028 - val_loss: 1.0175 - val_accuracy: 0.6701\n",
      "Epoch 56/200\n",
      "103/103 [==============================] - 35s 336ms/step - loss: 0.8436 - accuracy: 0.7212 - val_loss: 1.0221 - val_accuracy: 0.6646\n",
      "Epoch 57/200\n",
      "103/103 [==============================] - 36s 345ms/step - loss: 0.8591 - accuracy: 0.7163 - val_loss: 1.0289 - val_accuracy: 0.6638\n",
      "Epoch 58/200\n",
      "103/103 [==============================] - 34s 333ms/step - loss: 0.8374 - accuracy: 0.7273 - val_loss: 0.9632 - val_accuracy: 0.6859\n",
      "Epoch 59/200\n",
      "103/103 [==============================] - 36s 345ms/step - loss: 0.8431 - accuracy: 0.7199 - val_loss: 1.0639 - val_accuracy: 0.6543\n",
      "Epoch 60/200\n",
      "103/103 [==============================] - 36s 345ms/step - loss: 0.8511 - accuracy: 0.7251 - val_loss: 1.0536 - val_accuracy: 0.6614\n",
      "Epoch 61/200\n",
      "103/103 [==============================] - 34s 333ms/step - loss: 0.8220 - accuracy: 0.7316 - val_loss: 1.1387 - val_accuracy: 0.6511\n",
      "Epoch 62/200\n",
      "103/103 [==============================] - 35s 338ms/step - loss: 0.8267 - accuracy: 0.7316 - val_loss: 1.0325 - val_accuracy: 0.6661\n",
      "Epoch 63/200\n",
      "103/103 [==============================] - 34s 334ms/step - loss: 0.8071 - accuracy: 0.7297 - val_loss: 1.0448 - val_accuracy: 0.6740\n",
      "Epoch 64/200\n",
      "103/103 [==============================] - 34s 327ms/step - loss: 0.8079 - accuracy: 0.7303 - val_loss: 0.9566 - val_accuracy: 0.6875\n",
      "Epoch 65/200\n",
      "103/103 [==============================] - 35s 339ms/step - loss: 0.7945 - accuracy: 0.7322 - val_loss: 0.8899 - val_accuracy: 0.7064\n",
      "Epoch 66/200\n",
      "103/103 [==============================] - 35s 335ms/step - loss: 0.7983 - accuracy: 0.7288 - val_loss: 1.0486 - val_accuracy: 0.6677\n",
      "Epoch 67/200\n",
      "103/103 [==============================] - 35s 335ms/step - loss: 0.8135 - accuracy: 0.7264 - val_loss: 0.9662 - val_accuracy: 0.6803\n",
      "Epoch 68/200\n",
      "103/103 [==============================] - 34s 331ms/step - loss: 0.7818 - accuracy: 0.7313 - val_loss: 1.0922 - val_accuracy: 0.6646\n",
      "Epoch 69/200\n",
      "103/103 [==============================] - 33s 324ms/step - loss: 0.7845 - accuracy: 0.7358 - val_loss: 0.9873 - val_accuracy: 0.6827\n",
      "Epoch 70/200\n",
      "103/103 [==============================] - 34s 331ms/step - loss: 0.7743 - accuracy: 0.7377 - val_loss: 1.0292 - val_accuracy: 0.6725\n",
      "Epoch 71/200\n",
      "103/103 [==============================] - 34s 333ms/step - loss: 0.7971 - accuracy: 0.7398 - val_loss: 0.9391 - val_accuracy: 0.7072\n",
      "Epoch 72/200\n",
      "103/103 [==============================] - 35s 338ms/step - loss: 0.7506 - accuracy: 0.7496 - val_loss: 0.9889 - val_accuracy: 0.6867\n",
      "Epoch 73/200\n",
      "103/103 [==============================] - 35s 336ms/step - loss: 0.7738 - accuracy: 0.7313 - val_loss: 1.0596 - val_accuracy: 0.6654\n",
      "Epoch 74/200\n",
      "103/103 [==============================] - 35s 339ms/step - loss: 0.7507 - accuracy: 0.7447 - val_loss: 0.9540 - val_accuracy: 0.7048\n",
      "Epoch 75/200\n",
      "103/103 [==============================] - 34s 330ms/step - loss: 0.7373 - accuracy: 0.7533 - val_loss: 0.9431 - val_accuracy: 0.7056\n",
      "Epoch 76/200\n",
      "103/103 [==============================] - 34s 333ms/step - loss: 0.7254 - accuracy: 0.7582 - val_loss: 0.9042 - val_accuracy: 0.7080\n",
      "Epoch 77/200\n",
      "103/103 [==============================] - 35s 337ms/step - loss: 0.7742 - accuracy: 0.7478 - val_loss: 0.9027 - val_accuracy: 0.7103\n",
      "Epoch 78/200\n",
      "103/103 [==============================] - 34s 332ms/step - loss: 0.7133 - accuracy: 0.7640 - val_loss: 0.9352 - val_accuracy: 0.6961\n",
      "Epoch 79/200\n",
      "103/103 [==============================] - 35s 337ms/step - loss: 0.7077 - accuracy: 0.7582 - val_loss: 1.0113 - val_accuracy: 0.6796\n",
      "Epoch 80/200\n",
      "103/103 [==============================] - 34s 329ms/step - loss: 0.7433 - accuracy: 0.7594 - val_loss: 0.9216 - val_accuracy: 0.7096\n",
      "Epoch 81/200\n",
      "103/103 [==============================] - 34s 330ms/step - loss: 0.7114 - accuracy: 0.7658 - val_loss: 0.9478 - val_accuracy: 0.7096\n",
      "Epoch 82/200\n",
      "103/103 [==============================] - 34s 329ms/step - loss: 0.7144 - accuracy: 0.7591 - val_loss: 1.0182 - val_accuracy: 0.6890\n",
      "Epoch 83/200\n",
      "103/103 [==============================] - 35s 336ms/step - loss: 0.6966 - accuracy: 0.7542 - val_loss: 0.9096 - val_accuracy: 0.7143\n",
      "Epoch 84/200\n",
      "103/103 [==============================] - 34s 330ms/step - loss: 0.6887 - accuracy: 0.7665 - val_loss: 0.9900 - val_accuracy: 0.6938\n",
      "Epoch 85/200\n",
      "103/103 [==============================] - 40s 386ms/step - loss: 0.7143 - accuracy: 0.7594 - val_loss: 0.9558 - val_accuracy: 0.7017\n",
      "Epoch 86/200\n",
      "103/103 [==============================] - 34s 329ms/step - loss: 0.6951 - accuracy: 0.7649 - val_loss: 0.9629 - val_accuracy: 0.7080\n",
      "Epoch 87/200\n",
      "103/103 [==============================] - 36s 353ms/step - loss: 0.6799 - accuracy: 0.7732 - val_loss: 0.9156 - val_accuracy: 0.7135\n",
      "Epoch 88/200\n",
      "103/103 [==============================] - 40s 389ms/step - loss: 0.6824 - accuracy: 0.7668 - val_loss: 1.0552 - val_accuracy: 0.6788\n",
      "Epoch 89/200\n",
      "103/103 [==============================] - 45s 439ms/step - loss: 0.6766 - accuracy: 0.7707 - val_loss: 1.0319 - val_accuracy: 0.6811\n",
      "Epoch 90/200\n",
      "103/103 [==============================] - 44s 424ms/step - loss: 0.6879 - accuracy: 0.7689 - val_loss: 0.9307 - val_accuracy: 0.7111\n",
      "Epoch 91/200\n",
      "103/103 [==============================] - 40s 391ms/step - loss: 0.6526 - accuracy: 0.7784 - val_loss: 1.0258 - val_accuracy: 0.6930\n",
      "Epoch 92/200\n",
      "103/103 [==============================] - 39s 382ms/step - loss: 0.6607 - accuracy: 0.7738 - val_loss: 1.0753 - val_accuracy: 0.6867\n",
      "Epoch 93/200\n",
      "103/103 [==============================] - 38s 371ms/step - loss: 0.6466 - accuracy: 0.7839 - val_loss: 1.0361 - val_accuracy: 0.6859\n",
      "Epoch 94/200\n",
      "103/103 [==============================] - 35s 336ms/step - loss: 0.6596 - accuracy: 0.7674 - val_loss: 0.9507 - val_accuracy: 0.6993\n",
      "Epoch 95/200\n",
      "103/103 [==============================] - 38s 369ms/step - loss: 0.6340 - accuracy: 0.7824 - val_loss: 0.9512 - val_accuracy: 0.7017\n",
      "Epoch 96/200\n",
      "103/103 [==============================] - 36s 347ms/step - loss: 0.6092 - accuracy: 0.7971 - val_loss: 0.9727 - val_accuracy: 0.6977\n",
      "Epoch 97/200\n",
      "103/103 [==============================] - 36s 346ms/step - loss: 0.6337 - accuracy: 0.7879 - val_loss: 1.1827 - val_accuracy: 0.6717\n",
      "Epoch 98/200\n",
      "103/103 [==============================] - 37s 359ms/step - loss: 0.6102 - accuracy: 0.7925 - val_loss: 1.0291 - val_accuracy: 0.6898\n",
      "Epoch 99/200\n",
      "103/103 [==============================] - 35s 339ms/step - loss: 0.6529 - accuracy: 0.7851 - val_loss: 0.9159 - val_accuracy: 0.7190\n",
      "Epoch 100/200\n",
      "103/103 [==============================] - 36s 350ms/step - loss: 0.6165 - accuracy: 0.7992 - val_loss: 1.0074 - val_accuracy: 0.7009\n",
      "Epoch 101/200\n",
      "103/103 [==============================] - 44s 425ms/step - loss: 0.5974 - accuracy: 0.7968 - val_loss: 0.9675 - val_accuracy: 0.7024\n",
      "Epoch 102/200\n",
      "103/103 [==============================] - 49s 472ms/step - loss: 0.6065 - accuracy: 0.7928 - val_loss: 0.9528 - val_accuracy: 0.7009\n",
      "Epoch 103/200\n",
      "103/103 [==============================] - 40s 389ms/step - loss: 0.5912 - accuracy: 0.8047 - val_loss: 1.1393 - val_accuracy: 0.6827\n",
      "Epoch 104/200\n",
      "103/103 [==============================] - 41s 399ms/step - loss: 0.5942 - accuracy: 0.8013 - val_loss: 1.0177 - val_accuracy: 0.7009\n",
      "Epoch 105/200\n",
      "103/103 [==============================] - 37s 355ms/step - loss: 0.5897 - accuracy: 0.7983 - val_loss: 0.9683 - val_accuracy: 0.7143\n",
      "Epoch 106/200\n",
      "103/103 [==============================] - 35s 340ms/step - loss: 0.6524 - accuracy: 0.7799 - val_loss: 1.0492 - val_accuracy: 0.6922\n",
      "Epoch 107/200\n",
      "103/103 [==============================] - 38s 364ms/step - loss: 0.5974 - accuracy: 0.7958 - val_loss: 0.9415 - val_accuracy: 0.7127\n",
      "Epoch 108/200\n",
      "103/103 [==============================] - 39s 376ms/step - loss: 0.5640 - accuracy: 0.8102 - val_loss: 1.0025 - val_accuracy: 0.6914\n",
      "Epoch 109/200\n",
      "103/103 [==============================] - 38s 367ms/step - loss: 0.5605 - accuracy: 0.8157 - val_loss: 0.9726 - val_accuracy: 0.7080\n",
      "Epoch 110/200\n",
      "103/103 [==============================] - 36s 345ms/step - loss: 0.5814 - accuracy: 0.8010 - val_loss: 1.0588 - val_accuracy: 0.6946\n",
      "Epoch 111/200\n",
      "103/103 [==============================] - 36s 351ms/step - loss: 0.5659 - accuracy: 0.8084 - val_loss: 0.9761 - val_accuracy: 0.7253\n",
      "Epoch 112/200\n",
      "103/103 [==============================] - 35s 343ms/step - loss: 0.6139 - accuracy: 0.7888 - val_loss: 0.9980 - val_accuracy: 0.7088\n",
      "Epoch 113/200\n",
      "103/103 [==============================] - 38s 367ms/step - loss: 0.5647 - accuracy: 0.8032 - val_loss: 1.0639 - val_accuracy: 0.6890\n",
      "Epoch 114/200\n",
      "103/103 [==============================] - 37s 357ms/step - loss: 0.5629 - accuracy: 0.8041 - val_loss: 1.2133 - val_accuracy: 0.6725\n",
      "Epoch 115/200\n",
      "103/103 [==============================] - 37s 360ms/step - loss: 0.5524 - accuracy: 0.8139 - val_loss: 0.9771 - val_accuracy: 0.7056\n",
      "Epoch 116/200\n",
      "103/103 [==============================] - 37s 353ms/step - loss: 0.5601 - accuracy: 0.8053 - val_loss: 1.1478 - val_accuracy: 0.6717\n",
      "Epoch 117/200\n",
      "103/103 [==============================] - 35s 338ms/step - loss: 0.5444 - accuracy: 0.8087 - val_loss: 1.0864 - val_accuracy: 0.6914\n",
      "Epoch 118/200\n",
      "103/103 [==============================] - 34s 332ms/step - loss: 0.5447 - accuracy: 0.8118 - val_loss: 0.9136 - val_accuracy: 0.7285\n",
      "Epoch 119/200\n",
      "103/103 [==============================] - 35s 335ms/step - loss: 0.5444 - accuracy: 0.8225 - val_loss: 0.9537 - val_accuracy: 0.7127\n",
      "Epoch 120/200\n",
      "103/103 [==============================] - 34s 329ms/step - loss: 0.5741 - accuracy: 0.8111 - val_loss: 1.0589 - val_accuracy: 0.6906\n",
      "Epoch 121/200\n",
      "103/103 [==============================] - 34s 332ms/step - loss: 0.5340 - accuracy: 0.8124 - val_loss: 0.9216 - val_accuracy: 0.7238\n",
      "Epoch 122/200\n",
      "103/103 [==============================] - 35s 335ms/step - loss: 0.5316 - accuracy: 0.8148 - val_loss: 1.2153 - val_accuracy: 0.6654\n",
      "Epoch 123/200\n",
      "103/103 [==============================] - 34s 331ms/step - loss: 0.5527 - accuracy: 0.8090 - val_loss: 1.0539 - val_accuracy: 0.6906\n",
      "Epoch 124/200\n",
      "103/103 [==============================] - 35s 340ms/step - loss: 0.5077 - accuracy: 0.8353 - val_loss: 1.0093 - val_accuracy: 0.7135\n",
      "Epoch 125/200\n",
      "103/103 [==============================] - 34s 332ms/step - loss: 0.5276 - accuracy: 0.8243 - val_loss: 0.8899 - val_accuracy: 0.7411\n",
      "Epoch 126/200\n",
      "103/103 [==============================] - 34s 329ms/step - loss: 0.5097 - accuracy: 0.8289 - val_loss: 0.9983 - val_accuracy: 0.7111\n",
      "Epoch 127/200\n",
      "103/103 [==============================] - 35s 338ms/step - loss: 0.4788 - accuracy: 0.8326 - val_loss: 1.0721 - val_accuracy: 0.7048\n",
      "Epoch 128/200\n",
      "103/103 [==============================] - 34s 333ms/step - loss: 0.5137 - accuracy: 0.8277 - val_loss: 0.9549 - val_accuracy: 0.7340\n",
      "Epoch 129/200\n",
      "103/103 [==============================] - 34s 329ms/step - loss: 0.5035 - accuracy: 0.8237 - val_loss: 1.1703 - val_accuracy: 0.6803\n",
      "Epoch 130/200\n",
      "103/103 [==============================] - 34s 332ms/step - loss: 0.5031 - accuracy: 0.8280 - val_loss: 1.0096 - val_accuracy: 0.7088\n",
      "Epoch 131/200\n",
      "103/103 [==============================] - 35s 337ms/step - loss: 0.4946 - accuracy: 0.8344 - val_loss: 1.0531 - val_accuracy: 0.6985\n",
      "Epoch 132/200\n",
      "103/103 [==============================] - 36s 344ms/step - loss: 0.4799 - accuracy: 0.8390 - val_loss: 1.0068 - val_accuracy: 0.7127\n",
      "Epoch 133/200\n",
      "103/103 [==============================] - 35s 340ms/step - loss: 0.5030 - accuracy: 0.8310 - val_loss: 1.0569 - val_accuracy: 0.7080\n",
      "Epoch 134/200\n",
      "103/103 [==============================] - 38s 367ms/step - loss: 0.5075 - accuracy: 0.8240 - val_loss: 1.0192 - val_accuracy: 0.7174\n",
      "Epoch 135/200\n",
      "103/103 [==============================] - 36s 352ms/step - loss: 0.4740 - accuracy: 0.8411 - val_loss: 0.9202 - val_accuracy: 0.7388\n",
      "Epoch 136/200\n",
      "103/103 [==============================] - 36s 351ms/step - loss: 0.4676 - accuracy: 0.8445 - val_loss: 0.9725 - val_accuracy: 0.7269\n",
      "Epoch 137/200\n",
      "103/103 [==============================] - 36s 351ms/step - loss: 0.4656 - accuracy: 0.8387 - val_loss: 1.0165 - val_accuracy: 0.7080\n",
      "Epoch 138/200\n",
      "103/103 [==============================] - 36s 344ms/step - loss: 0.4657 - accuracy: 0.8384 - val_loss: 1.1323 - val_accuracy: 0.7127\n",
      "Epoch 139/200\n",
      "103/103 [==============================] - 35s 338ms/step - loss: 0.4914 - accuracy: 0.8344 - val_loss: 1.0462 - val_accuracy: 0.7143\n",
      "Epoch 140/200\n",
      "103/103 [==============================] - 35s 334ms/step - loss: 0.4794 - accuracy: 0.8365 - val_loss: 0.9300 - val_accuracy: 0.7285\n",
      "Epoch 141/200\n",
      "103/103 [==============================] - 34s 329ms/step - loss: 0.4540 - accuracy: 0.8479 - val_loss: 1.1652 - val_accuracy: 0.6930\n",
      "Epoch 142/200\n",
      "103/103 [==============================] - 34s 333ms/step - loss: 0.4606 - accuracy: 0.8451 - val_loss: 1.0095 - val_accuracy: 0.7285\n",
      "Epoch 143/200\n",
      "103/103 [==============================] - 37s 355ms/step - loss: 0.4542 - accuracy: 0.8365 - val_loss: 1.0212 - val_accuracy: 0.7245\n",
      "Epoch 144/200\n",
      "103/103 [==============================] - 35s 340ms/step - loss: 0.4809 - accuracy: 0.8390 - val_loss: 1.0710 - val_accuracy: 0.7096\n",
      "Epoch 145/200\n",
      "103/103 [==============================] - 34s 333ms/step - loss: 0.4740 - accuracy: 0.8347 - val_loss: 0.9946 - val_accuracy: 0.7301\n",
      "Epoch 146/200\n",
      "103/103 [==============================] - 35s 337ms/step - loss: 0.4610 - accuracy: 0.8460 - val_loss: 0.8898 - val_accuracy: 0.7403\n",
      "Epoch 147/200\n",
      "103/103 [==============================] - 34s 332ms/step - loss: 0.4227 - accuracy: 0.8528 - val_loss: 1.0016 - val_accuracy: 0.7285\n",
      "Epoch 148/200\n",
      "103/103 [==============================] - 35s 336ms/step - loss: 0.4532 - accuracy: 0.8445 - val_loss: 1.1220 - val_accuracy: 0.7024\n",
      "Epoch 149/200\n",
      "103/103 [==============================] - 34s 334ms/step - loss: 0.4065 - accuracy: 0.8610 - val_loss: 1.0831 - val_accuracy: 0.7214\n",
      "Epoch 150/200\n",
      "103/103 [==============================] - 35s 340ms/step - loss: 0.4512 - accuracy: 0.8408 - val_loss: 1.0596 - val_accuracy: 0.7167\n",
      "Epoch 151/200\n",
      "103/103 [==============================] - 35s 340ms/step - loss: 0.4418 - accuracy: 0.8473 - val_loss: 1.0357 - val_accuracy: 0.7127\n",
      "Epoch 152/200\n",
      "103/103 [==============================] - 35s 337ms/step - loss: 0.4517 - accuracy: 0.8445 - val_loss: 1.0896 - val_accuracy: 0.7103\n",
      "Epoch 153/200\n",
      "103/103 [==============================] - 35s 338ms/step - loss: 0.4402 - accuracy: 0.8479 - val_loss: 1.0080 - val_accuracy: 0.7309\n",
      "Epoch 154/200\n",
      "103/103 [==============================] - 35s 340ms/step - loss: 0.4210 - accuracy: 0.8509 - val_loss: 1.0098 - val_accuracy: 0.7245\n",
      "Epoch 155/200\n",
      "103/103 [==============================] - 35s 336ms/step - loss: 0.4348 - accuracy: 0.8497 - val_loss: 1.1708 - val_accuracy: 0.7024\n",
      "Epoch 156/200\n",
      "103/103 [==============================] - 35s 337ms/step - loss: 0.4345 - accuracy: 0.8497 - val_loss: 1.1020 - val_accuracy: 0.6985\n",
      "Epoch 157/200\n",
      "103/103 [==============================] - 35s 336ms/step - loss: 0.4721 - accuracy: 0.8332 - val_loss: 1.1466 - val_accuracy: 0.6788\n",
      "Epoch 158/200\n",
      "103/103 [==============================] - 35s 336ms/step - loss: 0.4488 - accuracy: 0.8494 - val_loss: 1.0534 - val_accuracy: 0.7174\n",
      "Epoch 159/200\n",
      "103/103 [==============================] - 34s 334ms/step - loss: 0.4182 - accuracy: 0.8595 - val_loss: 1.1445 - val_accuracy: 0.6969\n",
      "Epoch 160/200\n",
      "103/103 [==============================] - 35s 336ms/step - loss: 0.4171 - accuracy: 0.8604 - val_loss: 0.9514 - val_accuracy: 0.7427\n",
      "Epoch 161/200\n",
      "103/103 [==============================] - 35s 337ms/step - loss: 0.4361 - accuracy: 0.8405 - val_loss: 1.0210 - val_accuracy: 0.7214\n",
      "Epoch 162/200\n",
      "103/103 [==============================] - 35s 335ms/step - loss: 0.4122 - accuracy: 0.8583 - val_loss: 1.0556 - val_accuracy: 0.7309\n",
      "Epoch 163/200\n",
      "103/103 [==============================] - 35s 338ms/step - loss: 0.4185 - accuracy: 0.8641 - val_loss: 1.0884 - val_accuracy: 0.7119\n",
      "Epoch 164/200\n",
      "103/103 [==============================] - 35s 338ms/step - loss: 0.3902 - accuracy: 0.8678 - val_loss: 1.1333 - val_accuracy: 0.7096\n",
      "Epoch 165/200\n",
      "103/103 [==============================] - 35s 335ms/step - loss: 0.4003 - accuracy: 0.8580 - val_loss: 0.9564 - val_accuracy: 0.7403\n",
      "Epoch 166/200\n",
      "103/103 [==============================] - 35s 336ms/step - loss: 0.3825 - accuracy: 0.8678 - val_loss: 1.1201 - val_accuracy: 0.7190\n",
      "Epoch 167/200\n",
      "103/103 [==============================] - 35s 337ms/step - loss: 0.4004 - accuracy: 0.8561 - val_loss: 0.9243 - val_accuracy: 0.7506\n",
      "Epoch 168/200\n",
      "103/103 [==============================] - 34s 334ms/step - loss: 0.3715 - accuracy: 0.8754 - val_loss: 1.0141 - val_accuracy: 0.7253\n",
      "Epoch 169/200\n",
      "103/103 [==============================] - 35s 336ms/step - loss: 0.4312 - accuracy: 0.8515 - val_loss: 1.1421 - val_accuracy: 0.7222\n",
      "Epoch 170/200\n",
      "103/103 [==============================] - 35s 340ms/step - loss: 0.3853 - accuracy: 0.8705 - val_loss: 0.9948 - val_accuracy: 0.7364\n",
      "Epoch 171/200\n",
      "103/103 [==============================] - 35s 336ms/step - loss: 0.3866 - accuracy: 0.8620 - val_loss: 1.2236 - val_accuracy: 0.6985\n",
      "Epoch 172/200\n",
      "103/103 [==============================] - 35s 335ms/step - loss: 0.3837 - accuracy: 0.8739 - val_loss: 1.2685 - val_accuracy: 0.6875\n",
      "Epoch 173/200\n",
      "103/103 [==============================] - 35s 337ms/step - loss: 0.4092 - accuracy: 0.8598 - val_loss: 1.1174 - val_accuracy: 0.7253\n",
      "Epoch 174/200\n",
      "103/103 [==============================] - 35s 335ms/step - loss: 0.3770 - accuracy: 0.8702 - val_loss: 1.3465 - val_accuracy: 0.6843\n",
      "Epoch 175/200\n",
      "103/103 [==============================] - 34s 333ms/step - loss: 0.3956 - accuracy: 0.8711 - val_loss: 1.0496 - val_accuracy: 0.7135\n",
      "Epoch 176/200\n",
      "103/103 [==============================] - 35s 336ms/step - loss: 0.3791 - accuracy: 0.8730 - val_loss: 1.1218 - val_accuracy: 0.7040\n",
      "Epoch 177/200\n",
      "103/103 [==============================] - 35s 339ms/step - loss: 0.3716 - accuracy: 0.8705 - val_loss: 0.9633 - val_accuracy: 0.7395\n",
      "Epoch 178/200\n",
      "103/103 [==============================] - 35s 338ms/step - loss: 0.3603 - accuracy: 0.8727 - val_loss: 1.0722 - val_accuracy: 0.7316\n",
      "Epoch 179/200\n",
      "103/103 [==============================] - 35s 339ms/step - loss: 0.3557 - accuracy: 0.8776 - val_loss: 1.1468 - val_accuracy: 0.7198\n",
      "Epoch 180/200\n",
      "103/103 [==============================] - 35s 335ms/step - loss: 0.3870 - accuracy: 0.8730 - val_loss: 1.2143 - val_accuracy: 0.7040\n",
      "Epoch 181/200\n",
      "103/103 [==============================] - 35s 339ms/step - loss: 0.3620 - accuracy: 0.8788 - val_loss: 1.0524 - val_accuracy: 0.7285\n",
      "Epoch 182/200\n",
      "103/103 [==============================] - 35s 340ms/step - loss: 0.3732 - accuracy: 0.8748 - val_loss: 1.0653 - val_accuracy: 0.7293\n",
      "Epoch 183/200\n",
      "103/103 [==============================] - 34s 332ms/step - loss: 0.3428 - accuracy: 0.8834 - val_loss: 1.0247 - val_accuracy: 0.7514\n",
      "Epoch 184/200\n",
      "103/103 [==============================] - 35s 337ms/step - loss: 0.3864 - accuracy: 0.8662 - val_loss: 1.1733 - val_accuracy: 0.7088\n",
      "Epoch 185/200\n",
      "103/103 [==============================] - 35s 337ms/step - loss: 0.3580 - accuracy: 0.8776 - val_loss: 1.0941 - val_accuracy: 0.7395\n",
      "Epoch 186/200\n",
      "103/103 [==============================] - 34s 334ms/step - loss: 0.3604 - accuracy: 0.8742 - val_loss: 1.1958 - val_accuracy: 0.7127\n",
      "Epoch 187/200\n",
      "103/103 [==============================] - 35s 342ms/step - loss: 0.3608 - accuracy: 0.8754 - val_loss: 1.1350 - val_accuracy: 0.7135\n",
      "Epoch 188/200\n",
      "103/103 [==============================] - 35s 337ms/step - loss: 0.3357 - accuracy: 0.8837 - val_loss: 1.1405 - val_accuracy: 0.7301\n",
      "Epoch 189/200\n",
      "103/103 [==============================] - 34s 333ms/step - loss: 0.3524 - accuracy: 0.8794 - val_loss: 1.2202 - val_accuracy: 0.7151\n",
      "Epoch 190/200\n",
      "103/103 [==============================] - 35s 338ms/step - loss: 0.3238 - accuracy: 0.8895 - val_loss: 1.4446 - val_accuracy: 0.6851\n",
      "Epoch 191/200\n",
      "103/103 [==============================] - 35s 340ms/step - loss: 0.3628 - accuracy: 0.8745 - val_loss: 1.0042 - val_accuracy: 0.7474\n",
      "Epoch 192/200\n",
      "103/103 [==============================] - 35s 336ms/step - loss: 0.3618 - accuracy: 0.8766 - val_loss: 1.2332 - val_accuracy: 0.7167\n",
      "Epoch 193/200\n",
      "103/103 [==============================] - 35s 339ms/step - loss: 0.3434 - accuracy: 0.8776 - val_loss: 0.9878 - val_accuracy: 0.7537\n",
      "Epoch 194/200\n",
      "103/103 [==============================] - 35s 337ms/step - loss: 0.3368 - accuracy: 0.8867 - val_loss: 1.2161 - val_accuracy: 0.7127\n",
      "Epoch 195/200\n",
      "103/103 [==============================] - 34s 334ms/step - loss: 0.3347 - accuracy: 0.8831 - val_loss: 1.2987 - val_accuracy: 0.6953\n",
      "Epoch 196/200\n",
      "103/103 [==============================] - 35s 335ms/step - loss: 0.3392 - accuracy: 0.8855 - val_loss: 0.9865 - val_accuracy: 0.7466\n",
      "Epoch 197/200\n",
      "103/103 [==============================] - 35s 339ms/step - loss: 0.3373 - accuracy: 0.8895 - val_loss: 1.1581 - val_accuracy: 0.7261\n",
      "Epoch 198/200\n",
      "103/103 [==============================] - 35s 339ms/step - loss: 0.3263 - accuracy: 0.8834 - val_loss: 1.0497 - val_accuracy: 0.7466\n",
      "Epoch 199/200\n",
      "103/103 [==============================] - 35s 339ms/step - loss: 0.3747 - accuracy: 0.8733 - val_loss: 1.4514 - val_accuracy: 0.6930\n",
      "Epoch 200/200\n",
      "103/103 [==============================] - 35s 339ms/step - loss: 0.3498 - accuracy: 0.8818 - val_loss: 1.1511 - val_accuracy: 0.7269\n",
      "564/564 [==============================] - 2s 4ms/step - loss: 1.3581 - accuracy: 0.6968\n",
      "Test Loss: 1.3581442832946777\n",
      "Test Accuracy: 0.6968085169792175\n"
     ]
    }
   ],
   "source": [
    "#Model Architecture\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001), input_shape=(256, 256, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(train_dataset.num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(train_dataset.num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "class CustomEarlyStopping(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        accuracy = logs.get('accuracy')\n",
    "        val_accuracy = logs.get('val_accuracy')\n",
    "        if accuracy is not None and val_accuracy is not None:\n",
    "            if accuracy > 0.85 and val_accuracy > 0.85:\n",
    "                print(f\"\\nStopping training as both training accuracy and validation accuracy have exceeded 0.85: \\nTraining Accuracy: {accuracy}, Validation Accuracy: {val_accuracy}\")\n",
    "                self.model.stop_training = True\n",
    "\n",
    "custom_early_stopping = CustomEarlyStopping()\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=200,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[custom_early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation = model.evaluate(test_dataset)\n",
    "print(f\"Test Loss: {evaluation[0]}\")\n",
    "print(f\"Test Accuracy: {evaluation[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "564/564 [==============================] - 2s 3ms/step\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "            Bakso       1.00      0.22      0.36        50\n",
      "     Caesar Salad       0.62      0.70      0.66        50\n",
      "     Kerang Tiram       0.51      0.70      0.59        50\n",
      "             Nasi       0.91      0.81      0.85        36\n",
      "      Nasi Goreng       0.65      0.63      0.64        49\n",
      "        Sate Ayam       0.91      0.44      0.59        68\n",
      "Sayap Ayam Goreng       0.52      0.64      0.57        50\n",
      "           Siomay       0.70      0.78      0.74        51\n",
      "        Spaghetti       0.52      0.80      0.63        50\n",
      "            Steak       0.51      0.66      0.57        50\n",
      "     Telur Balado       0.60      0.30      0.40        10\n",
      "          Yoghurt       0.71      0.70      0.71        50\n",
      "\n",
      "         accuracy                           0.63       564\n",
      "        macro avg       0.68      0.62      0.61       564\n",
      "     weighted avg       0.69      0.63      0.62       564\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "predictions = model.predict(test_dataset)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "true_classes = test_dataset.classes\n",
    "class_labels = list(test_dataset.class_indices.keys())\n",
    "\n",
    "report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
